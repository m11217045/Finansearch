"""
æ¸¬è©¦ datetime JSON åºåˆ—åŒ–å•é¡Œä¿®å¾©
"""

import sys
import json
from datetime import datetime
sys.path.append('.')

def test_datetime_serialization():
    """æ¸¬è©¦ datetime ç‰©ä»¶çš„ JSON åºåˆ—åŒ–"""
    print("ğŸ§ª æ¸¬è©¦ datetime JSON åºåˆ—åŒ–ä¿®å¾©...")
    
    try:
        from src.utils import DateTimeEncoder
        
        # å‰µå»ºåŒ…å« datetime ç‰©ä»¶çš„æ¸¬è©¦æ•¸æ“š
        test_data = {
            'ticker': 'PDD',
            'analysis_time': datetime.now(),
            'news_data': [
                {
                    'title': 'æ¸¬è©¦æ–°è',
                    'publish_timestamp': datetime.now(),
                    'publish_time': '2024-01-01 10:00:00',
                    'content': 'æ¸¬è©¦å…§å®¹'
                }
            ],
            'metrics': {
                'created_at': datetime.now(),
                'pe_ratio': 15.5
            }
        }
        
        # æ¸¬è©¦åºåˆ—åŒ–
        json_str = json.dumps(test_data, cls=DateTimeEncoder, indent=2)
        print("âœ… JSON åºåˆ—åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦ååºåˆ—åŒ–
        parsed_data = json.loads(json_str)
        print("âœ… JSON ååºåˆ—åŒ–æˆåŠŸ")
        
        # æª¢æŸ¥ datetime æ˜¯å¦è¢«æ­£ç¢ºè½‰æ›ç‚ºå­—ä¸²
        if isinstance(parsed_data['analysis_time'], str):
            print("âœ… datetime ç‰©ä»¶å·²æ­£ç¢ºè½‰æ›ç‚ºå­—ä¸²")
        else:
            print("âŒ datetime ç‰©ä»¶è½‰æ›å¤±æ•—")
            return False
        
        print(f"ç¯„ä¾‹æ™‚é–“æˆ³: {parsed_data['analysis_time']}")
        return True
        
    except Exception as e:
        print(f"âŒ datetime åºåˆ—åŒ–æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_news_data_structure():
    """æ¸¬è©¦æ–°èæ•¸æ“šçµæ§‹åºåˆ—åŒ–"""
    print("\nğŸ“° æ¸¬è©¦æ–°èæ•¸æ“šçµæ§‹åºåˆ—åŒ–...")
    
    try:
        from src.enhanced_analyzer import EnhancedStockAnalyzer
        from src.utils import DateTimeEncoder
        import json
        
        # å‰µå»ºåˆ†æå™¨
        analyzer = EnhancedStockAnalyzer()
        
        # æ¨¡æ“¬æ–°èæ•¸æ“šï¼ˆåŒ…å«å¯èƒ½æœ‰å•é¡Œçš„ datetimeï¼‰
        mock_news = [
            {
                'title': 'æ¸¬è©¦æ–°è',
                'summary': 'æ¸¬è©¦æ‘˜è¦',
                'publisher': 'Test Publisher',
                'publish_time': '2024-01-01 10:00:00',
                'publish_timestamp': datetime.now(),
                'url': 'https://example.com',
                'source': 'Test',
                'content': 'æ¸¬è©¦å…§å®¹',
                'is_recent': True
            }
        ]
        
        # æ¸¬è©¦åºåˆ—åŒ–
        json_str = json.dumps(mock_news, cls=DateTimeEncoder, indent=2)
        print("âœ… æ–°èæ•¸æ“šåºåˆ—åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦ä¿å­˜åŠŸèƒ½
        test_results = {
            'ticker': 'TEST',
            'news_data': mock_news,
            'analysis_timestamp': datetime.now()
        }
        
        filepath = analyzer.save_analysis_results(test_results, "test_datetime_fix")
        if filepath:
            print(f"âœ… åˆ†æçµæœä¿å­˜æˆåŠŸ: {filepath}")
            return True
        else:
            print("âŒ åˆ†æçµæœä¿å­˜å¤±æ•—")
            return False
        
    except Exception as e:
        print(f"âŒ æ–°èæ•¸æ“šçµæ§‹æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_comprehensive_analysis():
    """æ¸¬è©¦å®Œæ•´çš„ç¶œåˆåˆ†æï¼ˆæ¨¡æ“¬ PDD çš„æƒ…æ³ï¼‰"""
    print("\nğŸ” æ¸¬è©¦å®Œæ•´ç¶œåˆåˆ†æ...")
    
    try:
        from src.enhanced_analyzer import EnhancedStockAnalyzer
        
        # å‰µå»ºåˆ†æå™¨
        analyzer = EnhancedStockAnalyzer()
        
        # æ¨¡æ“¬è‚¡ç¥¨æ•¸æ“š
        mock_stock_data = {
            'symbol': 'TEST',
            'name': 'Test Company',
            'current_price': 100.0,
            'market_cap': 1000000000,
            'trailing_pe': 15.5,
            'price_to_book': 2.0
        }
        
        # æ¨¡æ“¬åˆ†æï¼ˆä¸å¯¦éš›èª¿ç”¨ APIï¼‰
        mock_result = {
            'ticker': 'TEST',
            'company_name': 'Test Company',
            'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'overall_score': 75.5,
            'news_data': [
                {
                    'title': 'æ¸¬è©¦æ–°è',
                    'publish_timestamp': datetime.now(),
                    'source': 'Test'
                }
            ]
        }
        
        # æ¸¬è©¦ä¿å­˜
        filepath = analyzer.save_analysis_results({'TEST': mock_result}, "test_comprehensive")
        if filepath:
            print(f"âœ… ç¶œåˆåˆ†æçµæœä¿å­˜æˆåŠŸ: {filepath}")
            return True
        else:
            print("âŒ ç¶œåˆåˆ†æçµæœä¿å­˜å¤±æ•—")
            return False
        
    except Exception as e:
        print(f"âŒ ç¶œåˆåˆ†ææ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ datetime JSON åºåˆ—åŒ–ä¿®å¾©æ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦åŸºæœ¬ datetime åºåˆ—åŒ–
    basic_ok = test_datetime_serialization()
    
    # æ¸¬è©¦æ–°èæ•¸æ“šçµæ§‹
    news_ok = test_news_data_structure()
    
    # æ¸¬è©¦ç¶œåˆåˆ†æ
    comprehensive_ok = test_comprehensive_analysis()
    
    print(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
    print(f"åŸºæœ¬ datetime åºåˆ—åŒ–: {'âœ… é€šé' if basic_ok else 'âŒ å¤±æ•—'}")
    print(f"æ–°èæ•¸æ“šçµæ§‹åºåˆ—åŒ–: {'âœ… é€šé' if news_ok else 'âŒ å¤±æ•—'}")
    print(f"ç¶œåˆåˆ†æåºåˆ—åŒ–: {'âœ… é€šé' if comprehensive_ok else 'âŒ å¤±æ•—'}")
    
    if all([basic_ok, news_ok, comprehensive_ok]):
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼datetime JSON åºåˆ—åŒ–å•é¡Œå·²ä¿®å¾©")
        print("ğŸ“ ä¿®å¾©æ‘˜è¦:")
        print("- æ·»åŠ äº† DateTimeEncoder è‡ªå®šç¾© JSON ç·¨ç¢¼å™¨")
        print("- æ›´æ–°äº†æ‰€æœ‰ json.dump èª¿ç”¨ä½¿ç”¨æ–°ç·¨ç¢¼å™¨")
        print("- ä¿æŒ datetime ç‰©ä»¶åœ¨å…§å­˜ä¸­çš„åŸå§‹æ ¼å¼")
        print("- åªåœ¨åºåˆ—åŒ–æ™‚è½‰æ›ç‚º ISO æ ¼å¼å­—ä¸²")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¿®å¾©")
    
    print("\nğŸ æ¸¬è©¦å®Œæˆ")
